# 机器学习笔记

## 0 符号说明

- m = 训练样本数量
- x's = 输入变量或特征
- y's = 输出变量或目标变量
- $(x,y)$：训练样本（集合）
- $(x^{i},y^{i})$：第$i$个训练样本
- $x_j^{(i)}=$ 第$i$个训练样本的特征$j$的值
- $x^{(i)}=$ 第$i$个训练样本所有特征构成的列向量
- $n=|x^{(i)}|$：特征数量

## 1 机器学习介绍

1. 定义：
   - 机器学习是研究在没有显式编程的情况下，给予计算机学习能力的领域。——阿瑟·塞缪尔（Arthur Samuel）
   - 解决问题（T，Task）的程序能够通过对经验（E，Experience）的学习不断提高性能（P，Performance，由P度量）。——汤姆·M·米切尔 （Tom M. Mitchell）
     - 下国际象棋：
       - E = 多次下国际象棋的经验
       - T = 下国际象棋
       - P = 程序赢得下一次比赛的概率

2. 分类：
   - 监督学习（Supervised learning）：给定数据集，且已知数据样本的正确输出，需要找到输入输出之间的关系，有结果的反馈
     - 回归问题（regression）：预测连续输入的输出结果，输出是一个连续函数（例如：房价预测）
     - 分类问题（classification）：预测离散的输出结果，输出是一些离散的数值（例如：肿瘤类型分类）
   - 无监督学习（Unsupervised learning）：未知输出结果的类型，没有反馈

## 2 单变量线性回归

- 单变量线性回归（Linear Regression with One Variable），又被称为一元线性回归（univariate linear regression）
- 使用场合：**监督学习**，单输入（x），单输出（y）

### 2.1 假设函数（The Hypothesis Function）

$$
\hat y=h_\theta(x)=\theta_0+\theta_1x
$$

假设函数的图像是一条直线，即：我们建立了一个函数$h_\theta$，在确定参数$\theta_0,\theta_1$的情况下，尝试构造输入数据（x's）与输出数据（y's）间的**映射关系**。

### 2.2 代价函数（Cost Function）

- 作用：测量（量化）假设函数的准确性

$$
J(\theta_0,\theta_1)=\frac 1{2m}\sum_{i=1}^m(\hat y_i-y_i)^2=\frac 1{2m}\sum_{i=1}^m(h_\theta(x_i)-y_i)^2
$$

代价函数又被称为平方误差函数（Squared error function），或均方误差（Mean squared error）

损失函数中乘$\frac 1 2$是为了方便后续的梯度下降

- 目标：**最小化**代价函数$J(\theta_0,\theta_1)$，理想状态下，不存在误差时：$J(\theta_0,\theta_1)=0$

### 2.3 梯度下降（Gradient Descent）

- 作用、思路：通过调整参数$\theta_0,\theta_1$，逐步使代价函数最小化，期望到达损失函数的最小值点

- 方法：对损失函数求偏导数，沿着下降最快的方向（梯度方向），逐步降低损失函数的值，每一步下降的大小借助学习率$\alpha$进行控制

- 具体算法：
  $$
  \begin{aligned}\
  &\text{不断重复直到收敛}\{\\
  &\theta_j:=\theta_j-\alpha \frac \partial {\partial\theta_j}J(\theta),j=0,1,\dots,n\\
  &\}
  \end{aligned}
  $$

#### 2.3.1 针对单变量线性回归的梯度下降

$$
\begin{aligned}\
&\text{不断重复直到收敛}\{\\
&\theta_0:=\theta_0-\alpha \frac 1 m\sum_{i=1}^m(h_\theta(x_i)-y_i)\\
&\theta_1:=\theta_1-\alpha \frac 1 m\sum_{i=1}^m((h_\theta(x_i)-y_i)x_i)\\
&\}
\end{aligned}
$$

#### 2.3.2 单变量线性回归的梯度下降的可视化

https://www.youtube.com/watch?v=WnqQrPNYz5Q

## 3 线性代数回顾

- 矩阵
- 向量
- 矩阵加减乘（元素乘法、矩阵乘法）法
- 矩阵运算性质
- 矩阵的转置（`'`）与逆（`pinv`）

## 4 多变量线性回归

- 多变量线性回归（Linear Regression with Multiple Variables），又称为多元线性回归（multivariate linear regression）

### 4.1 假设函数

$$
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_2+\theta_3x_3+\cdots+\theta_nx_n
$$

写成矩阵（向量化）形式：
$$
h_\theta(x)=\begin{bmatrix}\theta_0&\theta_1&\dots&\theta_n\end{bmatrix}\begin{bmatrix}x_0\\x_1\\\vdots\\x_n\end{bmatrix}=\theta^Tx
$$
其中，$x_0^{(i)}=1,i=1,\dots,m$

当各训练样本以**行**的形式存储构成矩阵$X$时：
$$
X=
\begin{bmatrix}
x_0^{(1)}&x_1^{(1)}\\
x_0^{(2)}&x_1^{(2)}\\
x_0^{(3)}&x_1^{(3)}\\
\end{bmatrix},
\theta=
\begin{bmatrix}
\theta_0\\
\theta_1
\end{bmatrix}
$$
那么，有
$$
h_\theta(X)=X\theta
$$
后续课程中，$X$矩阵中的训练样本都将以行的形式存储。

### 4.2 代价函数

当参数向量$\theta\in\R^{n+1}$，代价函数为：
$$
J(\theta)=\frac 1 {2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2
$$
向量化形式为：
$$
J(\theta)=\frac 1 {2m}(X\theta-\stackrel{\rightarrow} y)^T(X\theta-\stackrel{\rightarrow} y)
$$
其中，$\stackrel{\rightarrow}y$为包含所以$y$值的向量

### 4.3 多变量线性回归的梯度下降

$$
\begin{aligned}\
&\text{不断重复直到收敛}\{\\
&\theta_0:=\theta_0-\alpha \frac 1 m\sum_{i=1}^m((h_\theta(x^{(i)})-y^{(i)})x_0^{(i)})\\
&\theta_1:=\theta_1-\alpha \frac 1 m\sum_{i=1}^m((h_\theta(x^{(i)})-y^{(i)})x_1^{(i)})\\
&\theta_2:=\theta_2-\alpha \frac 1 m\sum_{i=1}^m((h_\theta(x^{(i)})-y^{(i)})x_2^{(i)})\\
&\dots\\
&\}
\end{aligned}
$$

以上各式可以改写成下列形式：
$$
\theta:=\theta-\alpha \nabla J(\theta)
$$
其中，$\nabla J(\theta)$为以下列向量：
$$
\nabla J(\theta)=
\begin{bmatrix}
\frac{\partial J(\theta)}{\partial\theta_0}\\
\frac{\partial J(\theta)}{\partial\theta_1}\\
\vdots\\
\frac{\partial J(\theta)}{\partial\theta_n}\\
\end{bmatrix}
$$
列向量的第$j$个元素为：
$$
\frac{\partial J(\theta)}{\partial\theta_j}=\frac 1 m ((h_\theta(x^{(i)})-y^{(i)})x_j^{(i)})=\frac 1 m \sum_{i=1}^mx_j^{(i)}(h_\theta(x^{(i)})-y^{(i)})
$$
将以上两式写成矩阵形式：
$$
\frac{\partial J(\theta)}{\partial\theta_j}=\frac 1 m \stackrel{\rightarrow}x_j^T(X\theta-\stackrel{\rightarrow}y)\\
\nabla J(\theta)=\frac 1 m X^T(X\theta-\stackrel{\rightarrow}y)
$$
其中：$\stackrel{\rightarrow}x_j$为矩阵$X$第$j$列对应的列向量。

于是，我们最终得到多变量线性回归的梯度下降的矩阵形式：
$$
\theta:=\theta-\frac \alpha mX^T(X\theta-\stackrel {\rightarrow}y)
$$

### 4.4 特征标准化（Feature Normalization）

输入数据在数量级上相似能提高梯度下降的收敛速度，因为$\theta$在数据范围较小时较快收敛、在范围较大时收敛缓慢。在数量级相差特别悬殊时，还可能会出现震荡下降的情况。为防止此类现象的发生，我们可以对输入数据的范围进行手动调整。输入数据的理想范围为：$-1\leq x_i\leq 1$或$-0.5\leq x_i\leq 0.5$，对输入数据进行调整有两种方法：特征缩放与均值归一化。

#### 4.4.1 特征缩放（Feature Scaling）

$$
x_i:=\frac{x_i} {s_i}
$$

其中，$s_i$为数据范围（$\max-\min$）

#### 4.4.2 均值归一化（Mean Normalization）

$$
x_i:=\frac{x_i-\mu_i}{s_i}
$$

其中，$\mu_i$为特征$i$的所有值的平均，$s_i$为数据范围（$\max-\min$）

### 4.5 多项式回归（Polynomial Regression）

通过合并多个特征，可以增加特征数量，继而改变假设函数，如将$x_1$和$x_2$合并为$x_3=x_1x_2$。

此外，还可以改变特征的表示形式，使特征函数非线性。例如：
$$
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_1^2(x_2=x_1^2)\\
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2x_1^3(x_2=x_1^3)\\
h_\theta(x)=\theta_0+\theta_1x_1+\theta_2\sqrt {x_1}(x_2=\sqrt{x_1})
$$

### 4.6 正规方程（Normal Equation）

借助正规方程，无需迭代，可以直接计算得到最优的$\theta$。
$$
\theta=(X^TX)^{-1}X^Ty
$$
使用正规方程前，也无需进行特征缩放。

#### 4.6.1 对比：梯度下降与正规方程

| 梯度下降               | 正规方程                         |
| ---------------------- | -------------------------------- |
| 需要选择学习率$\alpha$ | 无需选择学习率$\alpha$           |
| 需要多次迭代           | 无需迭代                         |
| $O(kn^2)$              | $O(n^3)$，因为需要计算$X^TX$的逆 |
| $n$很大时依然工作良好  | $n$较大时十分缓慢                |

#### 4.6.2 正规方程的不可逆性

使用`pinv`而不是`inv`指令去计算矩阵的（伪）逆，但矩阵$X^TX$仍然可能不可逆，原因可能为：

- 存在冗余的特征，即存在两个相关度很高的特征（如：两个特征间线性相关），需要删除其中一个特征即可。
- 存在过多的特征（如：$m\leq n$），删除多余的特征，或使用正则化（regularization）。

## 5 Octave教程

（略）

## 6 逻辑回归（Logistic Regression）

- 用于分类问题，而不是回归问题

### 6.1 二元分类（Binary Classification）

- 输出值：$y\in\{0,1\}$，0通常表示负类别，1通常表示正类别
- 实现方法：
  - 使用线性回归，将大于等于0.5的归为1，小于0.5的归为0，分类效果不佳，原因是分类并不是一个线性函数；
  - 将Sigmoid函数（Logistic函数）作为假设函数的一部分

#### 6.1.1 假设函数形式

- 满足$0\leq h_\theta(x)\leq 1$

使用Sigmoid函数，假设函数如下：
$$
h_\theta(x)=g(\theta^Tx)\\
z=\theta^Tx\\
g(z)=\frac{1}{1+e^{-z}}
$$
$h_\theta$的值代表输出为1的概率。例如$h_\theta(x)=0.7$指输出有70%的概率为1.

一些有用的性质如下：
$$
h_\theta(x)=P(y=1|x;\theta)=1-P(y=0|x;\theta)\\
P(y=0|x;\theta)+P(y=1|x;\theta)=1
$$

#### 6.1.2 决策边界（Decision Boundary）

- 由假设函数得到，是区分$y=0$和$y=1$所在区域的边界线

由Sigmoid函数及假设函数，可得到以下性质：
$$
\theta^Tx\geq 0\Rightarrow y=1\\
\theta^Tx<0\Rightarrow y=0
$$

#### 6.1.3 代价函数

$$
J(\theta)=\frac 1 m\sum_{i=1}^m\text{Cost}(h_\theta(x^{(i)}),y^{(i)})\\
$$

其中：
$$
\text{Cost}(h_\theta(x),y)=-\log(h_\theta(x)),y=1\\
\text{Cost}(h_\theta(x),y)=-\log(1-h_\theta(x)),y=0
$$


![1](C:\Users\enquan\Desktop\Machine Learning\1.png)

![2](C:\Users\enquan\Desktop\Machine Learning\2.png)

根据以上图像及分析，有：
$$
\text{Cost}(h_\theta(x^{(i)}),y)=0\Rightarrow h_\theta(x)\\
\text{Cost}(h_\theta(x^{(i)}),y)\to \infty \Rightarrow y=0且h_\theta(x)\to 1\\
\text{Cost}(h_\theta(x^{(i)}),y)\to \infty \Rightarrow y=1且h_\theta(x)\to 0
$$

#### 6.1.4 简化的代价函数

将6.1.3节中的损失函数合并为一个式子：
$$
\text{Cost}(h_\theta(x),y)=-y\log(h_\theta(x))-(1-y)\log(1-h_\theta(x))
$$
于是，代价函数如下：
$$
J(\theta)=-\frac 1 m\sum_{i=1}^m[y^{(i)}\log(h_\theta(x^{(i)}))+(1-y^{(i)})\log(1-h_\theta(x^{(i)})]
$$
向量化形式如下：
$$
h=g(X\theta)\\
J(\theta)=\frac 1 m(-y^T\log(h)-(1-y)^T\log(1-h))
$$

#### 6.1.5 梯度下降

回顾梯度下降的一般形式，针对6.1.4节中的损失函数，可得：
$$
\begin{aligned}\
&\text{重复}\{\\
&\theta_j:=\theta_j- \frac \alpha m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}\\
&\}
\end{aligned}
$$
其向量化形式为：
$$
\theta:=\theta-\frac \alpha mX^T(g(X\theta)-\stackrel{\rightarrow}y)
$$
进一步可知
$$
\nabla J(\theta)=\frac 1 mX^T(g(X\theta)-\stackrel{\rightarrow}y)
$$

### 6.2 高级优化算法

- 共轭梯度法：Conjugate gradient
- BFGS
- L-BFGS

### 6.3 多元分类

- 策略：One-vs-all
- 思路：将问题分解为$n+1$个二分类问题
- 输出值：$y\in\{0,1,\dots,n\}$

- 算法实现：
  $$
  y\in\{0,1,\dots,n\}\\
  h_\theta^{(0)}=P(y=0|x;\theta)\\
  h_\theta^{(1)}=P(y=1|x;\theta)\\
  \dots\\
  h_\theta^{(n)}=P(y=n|x;\theta)\\
  \text{predicition}=\max_i(h_\theta^{(i)}(x))
  $$



## 7 正则化（Regularization）

正则化是用于解决过拟合的问题。

线性回归与逻辑回归可能存在以下三种情况：

- 欠拟合（underfitting），又被称为高偏差（high bias）：假设函数$h$与数据趋势的拟合度较差。通常是由于假设函数$h$过于简单，或使用了太少的特征
- 过拟合（overfitting），又被称为高方差（high variance）：假设函数$h$与现有数据拟合度较好，但泛化（generalize）能力较差，对新数据的预测性能较低。通常是由于假设函数$h$过于复杂，导致函数曲线存在许多与数据无关的不必要的拐弯或转角

- 刚刚好（just right）

解决过拟合的方法：

- 减少特征数量
  - 人工选择所需的特征
  - 使用模型选择算法，选择特征（主成分分析PCA等）
- 正则化
  - 保留所有特征，但降低各参数$\theta_j$，正则化在拥有许多有一定作用的特征时效果最佳。

正则化算法如下：
$$
\min_\theta\frac 1{2m}[\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2+\lambda\sum_{j=1}^n\theta_j^2]
$$
其中，$\lambda$为正则化参数（regularization parameter）

### 7.1 正则化线性回归（Regularized Linear Regression）

#### 7.1.1 正则化的梯度下降

$$
\begin{aligned}\
&\text{重复}\{\\
&\theta_0:=\theta_0-\alpha\frac 1 m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}\\
&\theta_j:=\theta_j-\alpha[(\frac 1 m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)})+\frac \lambda m\theta_j]\\
&j=1,2,\dots,n\\
&\}
\end{aligned}
$$

式中$\frac \lambda m\theta_j$为正则化操作项。**注意：**不对$\theta_0$进行正则化操作！

第二个式子也可化简为：
$$
\theta_j:=\theta_j(1-\alpha\frac \lambda m)-\alpha\frac 1 m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)}
$$
式中，$1-\alpha\frac \lambda m<1$，因此每次迭代都会降低参数$\theta_j$的值

#### 7.1.2 正则化的正规方程

$$
\theta=(X^TX+\lambda L)^{-1}X^Ty
$$

其中，
$$
L=
\begin{bmatrix}
0&&&&\\
&1&&&\\
&&1&&\\
&&&\ddots&\\
&&&&1
\end{bmatrix}
$$
回顾：在原本的正规方程中，如果$m\leq n$，$X^TX$将不可逆；但在添加了$\lambda L$项后，$X^TX+\lambda L$为可逆矩阵。

### 7.2 正则化逻辑回归（Regularized Logistic Regression）

#### 7.2.1 正则化的代价函数

$$
J(\theta)=-\frac 1 m \sum_{i=1}^m[y^{(i)}\log(h_\theta(x^{(i)}))+(1-y^{(i)})\log(1-h_\theta(x^{(i)}))]+\frac \lambda {2m}\sum_{j=1}^n\theta_j^2
$$

注意：在第二项求和中，排除了偏差项$\theta_0$

#### 7.2.2 正则化的梯度下降

$$
\begin{aligned}\
&\text{重复}\{\\
&\theta_0:=\theta_0-\alpha\frac 1 m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_0^{(i)}\\
&\theta_j:=\theta_j-\alpha[(\frac 1 m\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})x_j^{(i)})+\frac \lambda m\theta_j]\\
&j=1,2,\dots,n\\
&\}
\end{aligned}
$$

形式与正则化线性回归的梯度下降完全一致。

## 10 施行机器学习的建议

### 10.1 下一步的措施

预测结果不理想可以通过以下方法改进：

- 获取更多的训练数据
- 尝试减少特征
- 尝试增加特征
- 尝试多项式特征
- 提高或降低$\lambda$

以上方法的选取需要对现有的算法进行诊断，而不是随意选择。

### 10.2 评估假设函数

给定数据集，我们可以将其划分为两个子集：训练集（training set）和测试集（test set）

使用这两个集合，新的工作流程如下：

1. 使用训练集，学习得到参数$\Theta$，并最小化$J_{train}(\Theta)$
2. 计算测试集误差$J_{test}(\Theta)$

#### 10.2.1 不同类型的测试集误差

- 线性回归
  $$
  J_{test}(\Theta)=\frac 1 {2m_{test}}\sum_{i=1}^{m_{test}}(h_\Theta(x_{test}^{(i)})-y_{test}^{(i)})^2
  $$

- 分类问题
  $$
  err(h_\Theta(x),y)=
  \begin{cases}
  1,&h_\Theta(x)\geq 0.5且y=0,或h_\Theta(x)<0.5且y=1\\
  0,&其余情况
  \end{cases}
  $$
  $err(h_\Theta(x),y)$为分类错误率，于是测试集误差为：
  $$
  \text{Test error}=\frac 1 {m_{test}}\sum_{i=1}^{m_{test}}err(h_\Theta(x_{test}^{(i)}),y_{test}^{(i)})
  $$

### 10.3 模型选择、训练/验证/测试集

机器学习算法对训练数据的拟合程度好，无法说明其是一个好的算法，原因是：机器学习算法在其训练数据集的上的误差要比其他任何数据集要低。

为了选出效果最佳的学习算法，我们引入对于数据的第三个集合：交叉验证集（Cross Validation Set），简称为验证集

通常，将数据集按照以下比例进行划分：

- 训练集：60%
- 交叉验证集：20%
- 测试集：20%

因此，我们可以计算三个子集上的误差：
$$
测试集误差：J_{train}(\theta)=\frac 1 {2m}\sum_{i=1}^m(h_\theta(x^{(i)})-y^{(i)})^2\\
交叉验证集误差：J_{cv}(\theta)=\frac 1 {2m_{cv}}\sum_{i=1}^{m_{cv}}(h_\theta(x^{(i)}_{cv})-y^{(i)}_{cv})^2\\
测试集误差：J_{test}(\theta)=\frac 1 {2m_{test}}\sum_{i=1}^{m_{test}}(h_\theta(x^{(i)}_{test})-y^{(i)}_{test})^2
$$
选出不同阶次模型中最佳模型的步骤：

1. 使用训练集，计算不同阶次下模型的参数$\theta$，例如：模型的阶次$d$可为$d=1,2,\dots,10$；
2. 计算出以上各模型的交叉验证集误差，选出交叉验证集误差最小的模型；
3. 计算该模型的测试集误差$J_{test}(\Theta^{(d)})$，估计模型的泛化误差（generalization error）

注意：不能将交叉验证集用于设置正则化参数$\lambda$的验证曲线过程。

### 10.4 判断偏差或方差

- 随着多项式阶数$d$的提高，训练误差会降低；与此同时，交叉验证误差会先下降，到某个点后就会开始上升，呈现为凸函数。
- 高偏差（欠拟合）：$J_{train}(\Theta)$和$J_{cv}(\Theta)$都会较高，且$J_{cv}(\Theta)\approx J_{train}(\Theta)$
- 高方差（过拟合）：$J_{train}(\Theta)$较低，且$J_{cv}(\Theta)\gg J_{train}(\Theta)$

如下图所示：

![3](C:\Users\enquan\Desktop\Machine Learning\3.png)

### 10.5 正则化与偏差/方差

- $\lambda$过大：高偏差（欠拟合），$J_{train}(\Theta)$较低，且$J_{cv}(\Theta)\gg J_{train}(\Theta)$
- $\lambda$中等：刚刚好，$J_{train}(\Theta)$和$J_{cv}(\Theta)$都会较低，且$J_{cv}(\Theta)\approx J_{train}(\Theta)$
- $\lambda$过小：高方差（过拟合），$J_{train}(\Theta)$和$J_{cv}(\Theta)$都会较高

如下图所示：

![4](C:\Users\enquan\Desktop\Machine Learning\4.png)

为找到合适的模型及对应的正则化参数$\lambda$，方法如下：

1. 列出待选择的$\lambda$参数列表，如：$\lambda\in\{0,0.01,0.02,0.04,0.08,0.16,0.32,0.64,1.28,2.56,5.12,10.24\}$
2. 选择不同阶数、参数的模型，对各个模型，选用不同的$\lambda$进行学习，得到参数$\Theta$
3. 使用各组参数，在$\lambda=0$的情况下，计算$J_{cv}(\Theta)$
4. 选出$J_{cv}(\Theta)$最小的组合，并使用最佳的$\theta$与$\lambda$的组合，计算$J_{test}(\Theta)$，判断模型是否具有较好的泛化能力

### 10.6 学习曲线（Learning Curve）

高偏差（欠拟合）的情况下：

- 训练集数据量小：$J_{train}(\Theta)$小，但$J_{cv}(\Theta)$高
- 训练集数据量大：$J_{train}(\Theta)$和$J_{cv}(\Theta)$都会较高，且$J_{cv}(\Theta)\approx J_{train}(\Theta)$

高偏差的情况下，增加数据量并不能改善算法性能。

高方差（过拟合）的情况下：

- 训练集数据量小：$J_{train}(\Theta)$小，但$J_{cv}(\Theta)$高
- 训练集数据量大：随着训练集数据增加，$J_{train}(\Theta)$上升，而$J_{cv}(\Theta)$下降，直到到达一定的平台处，不再下降。此外，$J_{train}(\Theta)<J_{cv}(\Theta)$，两者始终保持着较大的差距

高方差的情况下，增加数据量有可能改善算法性能。

如下图所示：

![5](C:\Users\enquan\Desktop\Machine Learning\5.png)

![6](C:\Users\enquan\Desktop\Machine Learning\6.png)

### 10.7 回顾：下一步的措施

- 获取更多训练数据：改善高方差
- 使用较少的特征：改善高方差
- 增加特征：改善高偏差
- 增加多项式特征：改善高偏差
- 降低$\lambda$：改善高偏差
- 提高$\lambda$：改善高方差

## 11 机器学习系统设计

### 11.1 优先处理的工作

- 搜集大量数据
- 研究使用复杂的特征
- 开发以不同方式处理输入数据的算法

很难抉择哪项工作比较有用。

### 11.2 误差分析

通常，解决机器学习问题的推荐方法是：

- 使用简单的算法起步，迅速实现，尽早测试其性能；
- 绘制学习曲线，决定是否需要更多数据或特征等；
- 误差分析：手动检查交叉验证集的误差，尝试找到规律

注意：

- 需要使用单一数值作为衡量误差的指标，否则将难以评估算法的性能；
- 需要对输入数据进行处理，如：当输入是单词时，同一单词的不同形式应作为一个单词，可以使用词干提取软件完成（stemming software）

### 11.3 偏斜类（Skewed Classes）的误差指标

偏斜类（skewed classes）：两类标签的数据量差距悬殊，这种情况下使用准确率（Precision）和召回率（Recall）作为误差指标。

首先定义：

| 指标                   | 定义             |
| ---------------------- | ---------------- |
| 真正（True positive）  | 预测为1，实际为1 |
| 真负（True negative）  | 预测为0，实际为0 |
| 假负（False negative） | 预测为0，实际为1 |
| 假正（False positive） | 预测为1，实际为0 |

$$
准确率=\frac{\text{True Positives}}{\text{Total number of predicted positives}}=\frac{\text{True Positives}}{\text{True Positives+False positives}}
$$

$$
召回率=\frac{\text{True Positives}}{\text{Total number of actual positives}}=\frac{\text{True Positives}}{\text{True Positives+False negatives}}
$$

作为对比
$$
\text{Accuarcy}=\frac{\text{}}{\text{}}
$$


### 11.4 权衡准确率（Precision）和召回率（Recall）

$$
\text{F Score}=2\frac{PR}{P+R}
$$

### 11.5 机器学习数据

